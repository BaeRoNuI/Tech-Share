# 독수리 사진관 프로젝트 수행기 - #1
## 무슨 프로젝트인데?

![alt text](20240608-eagleFilm.png)

간단하게 말해서, 사진 여러장을 주면 ML 모델을 열심히 돌려서 AI 프로필 사진을 만들어주는 서비스 입니다. 

저는 이제 학생이 아니니까.. 원래는 참여를 안 하려고 했는데 팀장이 "너 아니면 할 사람 없어~~" 라는 말로 자꾸 저를 괴롭히더라고요.

결국 "설계는 내가 할테니 코딩할 다른 사람을 데려와라" 라고 하면서 기본적인 조건 몇개를 걸었는데, 아쉽게도 사람을 못 구해서 결국은 제가 독박 썼습니다 (??)

일반적인 서비스와 달리 GPU를 사용한다는 점, 그리고 ML을 담당한 분이 엔지니어링 보다는 리서치에 가까우셨기 때문에 서버의 역할이 좀 더 중요해 졌습니다.

이번과 다음 발표동안, 이 짧은 프로젝트에서 서버는 어떤 고민을 했는지/이 문제를 어떤 방식으로 해결했는지에 대해 설명하려고 합니다.

## 발생했던 문제들
~~결국은 서버가 다 함~~
이 프로젝트는 행사 전 까지 모델을 열심히 깎고, 행사 동안은 학습 완료된 모델을 Inference 하는 기본적인 구조를 띄고 있었습니다. 하지만 Inference 단계에서 생각보다 많은 시간 (과 GPU 자원)이 들었다는 점, 그리고 그 GPU가 후원 받은 GPU 였다는 점 때문에 다음과 같은 고민이 필요했습니다.

- 클라우드 GPU가 아닌, 실제 물리적 GPU를 할당 받았기 때문에, 중간에 GPU를 Cool-down 시킬 필요가 있음.
- 요청이 많아지면 다른 GPU를 공수해와서 추가적으로 Task를 할당해야 함.

또한, 자원의 특성상 잘못된 요청/어뷰징이 들어왔을 때의 Risk가 더 커지기 때문에, **접근제한 관점**에서 이전 서비스보다도 더욱 엄격한 정책이 필요했습니다.

마지막으로, 상술했듯 ML을 담당했던 분이 엔지니어링에 대한 경험이 많지 않았기 때문에, 모델 서버 측 개발 부담을 최소화 하면서도 위와 같은 요구사항을 모두 만족할 필요가 있었습니다.

## GPU의 State 정의하기
가장 먼저, 모델 서버 측에 "최소한"의 API를 할당하는 방법에 대해 고민했습니다. 최대한 프론트/미들 서버 측에서 가능한 한 많은 로직을 담당하고, 모델 서버는 최소한의 API 만 개발하도록 해 부담을 줄이는게 목적이었기 때문입니다.

일반적인 모델 서버라면, 다음과 같은 구상을 해 볼 수 있을 것 같습니다.
```mermaid

```

## GPU를 유동적으로 할당하기

## Graceful Shutdown

## GPU의 정합성 체크하기
